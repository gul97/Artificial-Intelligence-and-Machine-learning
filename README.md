# Artificial-Intelligence-and-Machine-learning will The Future of Healthcare
 
Contributed: The power of AI in surgery As the healthcare sector continues to expand, the volume and complexity of the data used grow exponentially. To deliver rapid and efficient medical care, healthcare providers must collect and access data accurately and quickly.

![image](https://user-images.githubusercontent.com/124528445/217019067-983d1b73-db58-4c03-8e05-1bcfb5158a3c.png)


Artificial intelligence (AI), defined as algorithms that allow machines to perform cognitive functions (such as difficulty-explaining and decision-making), has improved for some time now in the appearance of healthcare through machine learning (ML) and natural language processing (NLP).

However, compared to other medical specializations, it took longer for technology to be used in surgical procedures. This was mostly because there was a lack of information about the potential for computational implementation in real-world surgery. AI is currently seen as an addition to human surgeons' competence rather than a substitute because of the rapid advancements that have been recorded.

Although the relationship between the surgeon, patient, and machine has a lot of promise, using AI in surgery is already bringing about big improvements for both patients and doctors.

For instance, computed tomography (CT), ultrasound, and magnetic resonance imaging (MRI) have consistently improved surgical planning and navigation, while minimally invasive surgery (MIS), when used in conjunction with robotic assistance, has reduced surgical trauma and enhanced patient recovery.

## How AI is shaping preoperative planning

Surgeons arrange the surgical procedure during the preoperative planning phase using the patient's medical history and imaging. Deep learning, which has been utilized for anatomical categorization, detection segmentation, and image registration, is boosting this step, which combines broad image-analysis approaches and traditional machine learning for classification.
Calvarial fracture, cerebral bleeding, and midline shift were among the anomalies in CT scan that deep learning algorithms were able to recognize. Emergency care is made possible for these abnormalities because of deep learning, which also holds promise for the automation of triage in the future.
Deep learning recurrent neural networks (RNN), which have been used to forecast mortality and postoperative bleeding following cardiac surgery as well as renal failure in real-time, have shown better outcomes than conventional clinical reference methods.Collecting clinical data without manual processing can improve critical care by giving more attention to patients who are most at risk of developing this type of complication.

![image](https://user-images.githubusercontent.com/124528445/217024447-636ea706-0af6-47b5-a54d-d3be670767d8.png)

 
## AI's role in intraoperative guidance

Computer-assisted intraoperative guidance has always been the cornerstone of minimally invasive surgery (MIS).

 AI learning strategies have been implemented in several areas of his MIS, such as tissue tracking.

Accurate tracking of tissue deformation is critical for intraoperative guidance and navigation in MIS. Since tissue deformation cannot be accurately modeled with an extemporaneous representation, scientists have developed an online learning framework based on algorithms to identify tracking methods suitable for in vivo practice.

# The AI for Surgical Robotics

Owing to the development of AI technology, surgical robots can perform superhumanly during MIS. The goal of AI is to enhance the ability of surgical robotic systems to perceive complex in vivo environments, make decisions, and perform intended tasks with greater accuracy, safety, and efficiency. As shown in Figure 3, common AI techniques used in robotics and autonomous systems (RAS) are (1) perception, (2) localization and mapping, (3) system modeling and control, and (4) human–robot interaction.

![fmd-20021-zxy-fig3](https://user-images.githubusercontent.com/124528445/217026969-61924b26-5565-4d17-b828-813b464ebc51.jpg)

Designed to help out during operations with surgical gadgets' control and positioning, AI-driven surgical robots are computer-used devices that allow surgeons to attention to the complex aspects of surgery. 

Their use reduces surgeons' fluctuations for the duration of surgery and helps them enhance their skills and perform better during interventions, hence obtaining superior patient outcomes and decreasing overall healthcare expenditures.

With the support of ML techniques, surgical robots help detect critical perceptions and state-of-the-art methods by browsing through millions of data sets. Asensus Surgical has a performance-guided laparoscopic AI robot that provides information back to surgeons, such as the size of the tissue, rather than requiring a physical quantifying tape. At the same time, human skills are used for programming these robots by demonstration – and for instructing them by imitating operations performed by surgeons. 

![image](https://user-images.githubusercontent.com/124528445/217029011-347eba53-71b3-46c1-8bbb-072a0a12d546.png)

Learning from demonstration (LfD) is used for "training" robots to accomplish new tasks individually, based on the collected information. In the first stage, LfD splits a complex surgical task into various subtasks and basic gestures. In the second stage, surgical robots recognize the model and conduct the subtasks in chronological mode, hence providing human surgeons with a break from tiresome tasks.

The objective of expanding the use of autonomous robots in surgery and the tasks these robots act especially in MIS is a difficult endeavor. JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS) – the first public benchmark surgical activity dataset – featured kinematic data and corresponding video for three standard surgery tasks conducted by surgeons from Johns Hopkins University with different levels of surgical skills.
The kinematics and stereo video was taken. The subtasks examined were stitching, needle passing, and knot tying. The gestures – the smallest levels of a surgery's considerable sections – performed during the implementation of each subtask – were recognized with an accuracy of around 80%. The result, even though promising, indicated there is room for progress, especially in forecasting the gesture activities conducted by various surgeons.

For many surgical tasks, reinforcement learning (RL) is a frequently used machine-learning paradigm to solve subtasks, such as tube insertion and soft tissue movement, for which it is difficult to render precise critical models. RL algorithms are formatted based on policies learned from demonstrations, instead of learning from zero, hence lowering the time needed for the learning process.

# Cases of AI-supported surgery








